The system is demonstrated using a small set of example technical documentation PDFs. These documents are used to validate the retrieval and grounding behavior of the RAG pipeline rather than to provide a comprehensive knowledge base. The PDFs are preloaded at startup, text is extracted with pdfplumber (with an OCR fallback for image-heavy pages), then split into overlapping chunks and embedded using a sentence-transformer model. Embeddings are stored in a FAISS vector database, and user questions trigger semantic similarity search to retrieve the most relevant chunk(s). The app is built with Streamlit and supports optional LLM-based generation via a user-provided API key; if no key is provided, the system still validates the RAG pipeline by displaying the retrieved documentation content. Key challenges included handling image-based PDFs, preventing cross-document chunk mixing, and keeping sensitive documents/keys out of GitHubâ€”solved with OCR fallback, document boundary separation, and a strict .gitignore.
