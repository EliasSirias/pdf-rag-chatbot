This project implements a Retrieval-Augmented Generation (RAG) chatbot that answers user questions using the content of PDF documents. The PDFs are preloaded at startup, text is extracted with pdfplumber (with an OCR fallback for image-heavy pages), then split into overlapping chunks and embedded using a sentence-transformer model. Embeddings are stored in a FAISS vector database, and user questions trigger semantic similarity search to retrieve the most relevant chunk(s). The app is built with Streamlit and supports optional LLM-based generation via a user-provided API key; if no key is provided, the system still validates the RAG pipeline by displaying the retrieved documentation content. Key challenges included handling image-based PDFs, preventing cross-document chunk mixing, and keeping sensitive documents/keys out of GitHubâ€”solved with OCR fallback, document boundary separation, and a strict .gitignore.